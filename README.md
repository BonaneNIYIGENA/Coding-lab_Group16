# Coding-lab_Group16
Hospital Data Monitoring & Archival System

Project Overview

This project implements a foundational Hospital Data Monitoring & Archival System. Its core purpose is to simulate the collections of real-time patient health
metrics and resource usage data, Provide a structured method for archiving historical logs, and perform basic analysis to generate insightful reports. This system
serves as a demostration of proficiency in interactive shell scripting, robust log file processing, and data analysis using Linux command-line tools.

Project Objectives
The development of this system aimed to achieve the following specific objectives:

1. Real-time Data simulation: Utilize python scripts to simulate conntinous generation of vital patient health metrics (heart rate, temperature) and essentia
resource usage (water consumptions).

2. Controlled Log Archiving: Develop an interactive Bash script (archive_logs.sh) that allows users to selectively archive log files, ensuring data
persistence and maintaining historical records with clear timestamps.

3. Intelligent Data Analysis: Create an interactive Bsh script (analyze_logs.sh) to process both current and potentially archived log data, extracting key
statistics such as device occurrence counts and temporal patterns (first/last entry timestamps).

4. Automated Reporting: Implement functionality to append analysis results to dedicated report file, providing a clear summary of system activities and findings.

5. Demostrate Core Skills: Showcase practical application of shell scripting fundamentals, including user interaction (select, case), file manipulation
(mv, touch), data parsing (awk, cut), sorting (sort, uniq), and effetive error handling.

System Setup Guide

To get this system running on your local machine, follow these steps meticulously:

1. Clone the Repository 

Begin by cloning our group's project repository from GitHub. Navigat to your working directory in your terminal and execute:
git clone https://github.com/BonaneNIYIGENA/Coding-lab_Group16.git

purpose: This command downloads all projects file and the Git history into a new directory on your machine, named after your repository. Then 
cd then navigates you into this project root (Coding-lab_Group16).

Step 2. Create Required Directory Structure

The system relies on a specific hierarchy for organizing active logs, archived data, and reports. From the root directory of your cloned repository.
That's why is neccessary to create directory where they are going to run on.

mkdir -p hospital_data

Purpose: This directory will house all our files and generated one

Step 3 . Create Required File Structure

nano, vi, vim archive_logs.sh
nano, vi, vim analyze_logs.sh

Purpose: this archive_logs.sh will house the Bash scripts for archieve side then analyze_logs.sh will house the Bashscript for analyze and reports.

Step 4. Place Python Simulators 

The data for this system is generated by three python scripts. for proper execution and submissions compliance, these pythons files 

(nano, vi, vim heart_monitor.py
nano, vi, vim temp_sensor.py
nano, vi, vim water_meter.py) must be placec directly in the root directory of Coding-lab_Group16 repository.

These command of nano, vi, vim is for creating file and editing it, it depends on your choice of which command you want to use.

Purpose: While these scripts generates log data into a specific subdirectory(hospital_data/active_logs/),the python files themeslves are expected to reside at the 
top at the level of the project for easy execution.

Step 5. Start Data collection

This is critical step as your scripts operate on live log data. Open three separate terminals windows. In each terminal, navigate to the root of your 
repository and start simulator:

Terminal 1 (Heart Rate Monitor): 
python3 heart_monitor.py start

Terminal 2 (Temperature Sensor):
python3 temp_sensor.py start

Terminal 3 (Wter Meter):
python3 water_meter.py start

Purpose: These command initiate continous data generation. The python scripts will create real-time log entries to hospital_data/active_logs/heart_rate.log,
hospital_data/active_logs/temperature.log, and hospital_data/active_log/water_usage.log respectively. These terminals must remain open and running for the
system to collect data.

Step 6. Verify Data Collection

To confirm that logs are being actively generated, open fourth terminal and use the tail -f command:

tail -f hospital_data/active_logs/heart_rate.log
# You can also check temperature.log and water_usage.log similarly

Purpuse: tail -f display the last few lines of a file and then continuously outputs new lines as they are added. This allows you to monitor the live data stream
and confirm that the simulators are correctly writing to their log file.

System Functionalities (Scripts)

1. archive_logs.sh

Core Requirements Implemented:

Interactive Menu: Utilizes the select and case shell constructors to present a numbered menu to the user.
Log Type Selection: Allows archiving of heart_rate.log, temperature.log or water_usage.log

Archiving process
Move: Uses 'mv' to move the active log files.
Rename with Timestamp: Employs date command for timestamp generation (YYYY-MM-DD_HH:MM:SS format) and shell parameter expansion with basename to construct
the new archived filename (e.g., heart_rate_2024-06-18_15:22:10.log)
New Empty Log: Uses 'touch' to create a new. empty log file, ensuring the python simulators can continue writing without interruption.

Robust Error Handling:

Invalid User Input: The case statement catches non-numeric or out-of-range inputs.
Missing Log file: test -f is used to verify the existing of the active log file before attempting to mive it.
Archive Directory Issues: mkdir -p ensures the archive directory exists, and itx exit status is checked to handle creation/access errors.

How to use:

From the root of your repository, run the script

"./hospital_data/archive_logs.sh"

2. analyze_logs.sh (Task 2: Intelligent Analysis Script)

This script provides an interactive menu for the user to select which log file (from the active logs) they wish to analyze. Then processes the selected
log to count occurrences of each unique device and extracts their timestamps of the very first and last entries. All analysis results are appended to
a cumulative report file.

Core Requirements Implemented

Interactive Prompt: Uses 'select' and 'case' for user-friendly input.
Input Validation: Ensures only valid menu choices (1-3) are accepted.

Analysis Functionality:

Device Counting: Extract device names from log entries using 'awk' and then counts their occurrences using 'sort' and 'uniq -c'.
Timestamp Extraction: Retrieves the first and last lines of the log file using 'head' and 'tail' respectively, then parses the timestamps using
'awk' and 'tr'.

Reporting: All results are formatted and appended to reports/analysis_report.txt using output redirection (>>).
The report includes a header with the analysis time and details of the analyzed log.


How to use:

From the root of your repository, run the script

"./hospital_data/analyze_logs.sh"
